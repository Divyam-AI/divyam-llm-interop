# divyam-llm-interop
A lightweight, provider-neutral library for translating LLM requests and responses across model APIs. It automatically reconciles parameter differences—normalizing ranges, renaming fields, and dropping unsupported options—while preserving semantics. Supports bidirectional translation between OpenAI Chat Completions and the Responses API.
